import Foundation

class VolcanoLLMService {
    static let shared = VolcanoLLMService()

    private init() {}

    private var apiKey: String {
        KeychainHelper.shared.load(key: "volcano_api_key") ?? ""
    }

    // ç«å±±å¼•æ“è±†åŒ…å¤§æ¨¡å‹ API - Responses API
    // æ–‡æ¡£å‚è€ƒ: https://www.volcengine.com/docs/6291/65568
    func chat(messages: [Message], streaming: Bool = false, enableWebSearch: Bool = false) async throws -> String {
        guard !apiKey.isEmpty else {
            print("âŒ [LLM] æœªé…ç½®è®¤è¯ä¿¡æ¯ï¼")
            print("ğŸ’¡ è¯·æŒ‰ âŒ˜, æ‰“å¼€è®¾ç½®ï¼Œé…ç½®æ–¹èˆŸå¹³å°çš„ API Key")
            throw VolcanoError.missingAPIKey
        }

        return try await chatWithAPIKey(messages: messages, streaming: streaming, enableWebSearch: enableWebSearch)
    }

    // ä½¿ç”¨ API Key è®¤è¯ï¼ˆæ¨èï¼‰- Responses API
    private func chatWithAPIKey(messages: [Message], streaming: Bool, enableWebSearch: Bool) async throws -> String {
        print("ğŸ”‘ [LLM] ä½¿ç”¨ API Key è®¤è¯")
        print("ğŸ“ [LLM] å‡†å¤‡å‘é€ \(messages.count) æ¡æ¶ˆæ¯")

        // æ£€æµ‹æ˜¯å¦æœ‰å¤šæ¨¡æ€å†…å®¹ï¼ˆå›¾ç‰‡ï¼‰
        let hasMultimodalContent = messages.contains { $0.hasImages }

        // å¤šæ¨¡æ€ä½¿ç”¨ chat/completions APIï¼Œå…¶ä»–ä½¿ç”¨ responses API
        if hasMultimodalContent {
            return try await chatWithChatCompletionsAPI(messages: messages)
        } else {
            return try await chatWithResponsesAPI(messages: messages, enableWebSearch: enableWebSearch)
        }
    }

    // Chat Completions API - æ”¯æŒå¤šæ¨¡æ€
    private func chatWithChatCompletionsAPI(messages: [Message]) async throws -> String {
        print("ğŸ–¼ï¸ [LLM] ä½¿ç”¨ Chat Completions API (å¤šæ¨¡æ€æ¨¡å¼)")

        let urlString = "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
        print("ğŸ“¡ [LLM] API URL: \(urlString)")

        guard let url = URL(string: urlString) else {
            throw VolcanoError.invalidURL
        }

        // æ„å»ºæ¶ˆæ¯æ•°ç»„
        let messagesArray = messages.map { message -> [String: Any] in
            var messageDict: [String: Any] = ["role": message.role.rawValue]

            if message.hasImages {
                // å¤šæ¨¡æ€æ¶ˆæ¯ï¼šä½¿ç”¨ content æ•°ç»„
                var contentArray: [[String: Any]] = []

                // æ·»åŠ å›¾ç‰‡å†…å®¹
                for attachment in message.imageAttachments {
                    let base64URL = ImageProcessor.toBase64DataURL(data: attachment.data, mimeType: attachment.mimeType)
                    contentArray.append([
                        "type": "image_url",
                        "image_url": ["url": base64URL]
                    ])
                }

                // æ·»åŠ æ–‡æœ¬å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
                if !message.content.isEmpty {
                    contentArray.append([
                        "type": "text",
                        "text": message.content
                    ])
                }

                messageDict["content"] = contentArray
            } else {
                // çº¯æ–‡æœ¬æ¶ˆæ¯
                messageDict["content"] = message.content
            }

            return messageDict
        }

        let requestBody: [String: Any] = [
            "model": VolcanoConfig.modelName,
            "messages": messagesArray
        ]

        let imageCount = messages.reduce(0) { $0 + $1.imageAttachments.count }
        print("ğŸ–¼ï¸ [LLM] åŒ…å«å›¾ç‰‡: \(imageCount) å¼ ")
        print("ğŸ“¤ [LLM] æ¶ˆæ¯æ•°é‡: \(messages.count)")

        let jsonData = try JSONSerialization.data(withJSONObject: requestBody)

        let headers = [
            "Content-Type": "application/json",
            "Authorization": "Bearer \(apiKey)"
        ]

        do {
            let response: ChatCompletionsResponse = try await NetworkManager.shared.request(
                url: url,
                method: "POST",
                headers: headers,
                body: jsonData,
                responseType: ChatCompletionsResponse.self
            )

            print("âœ… [LLM] æ”¶åˆ°å“åº”")

            guard let firstChoice = response.choices.first,
                  let content = firstChoice.message.content else {
                print("âŒ [LLM] å“åº”ä¸­æ²¡æœ‰å†…å®¹")
                throw VolcanoError.emptyResponse
            }

            print("âœ… [LLM] æˆåŠŸè·å–å›å¤ï¼Œé•¿åº¦: \(content.count) å­—ç¬¦")

            if let usage = response.usage {
                print("ğŸ“Š [LLM] Token ä½¿ç”¨: è¾“å…¥=\(usage.prompt_tokens), è¾“å‡º=\(usage.completion_tokens), æ€»è®¡=\(usage.total_tokens)")
            }

            return content
        } catch let error as URLError {
            print("âŒ [LLM] ç½‘ç»œé”™è¯¯: \(error.localizedDescription)")
            throw VolcanoError.requestFailed("ç½‘ç»œé”™è¯¯: \(error.localizedDescription)")
        } catch let error as DecodingError {
            print("âŒ [LLM] å“åº”è§£æå¤±è´¥: \(error)")
            throw VolcanoError.requestFailed("å“åº”æ ¼å¼é”™è¯¯")
        } catch {
            print("âŒ [LLM] é”™è¯¯: \(error)")
            throw error
        }
    }

    // Responses API - æ”¯æŒè”ç½‘æœç´¢
    private func chatWithResponsesAPI(messages: [Message], enableWebSearch: Bool) async throws -> String {
        print("ğŸ“ [LLM] ä½¿ç”¨ Responses API")
        if enableWebSearch {
            print("ğŸŒ [LLM] å·²å¯ç”¨è”ç½‘æœç´¢")
        }

        let urlString = "https://ark.cn-beijing.volces.com/api/v3/responses"
        print("ğŸ“¡ [LLM] API URL: \(urlString)")

        guard let url = URL(string: urlString) else {
            throw VolcanoError.invalidURL
        }

        var requestBody: [String: Any] = [
            "model": VolcanoConfig.modelName
        ]

        if enableWebSearch {
            // è”ç½‘æœç´¢æ¨¡å¼ï¼šä½¿ç”¨æ•°ç»„æ ¼å¼
            let inputMessages = messages.map { message in
                ["role": message.role.rawValue, "content": message.content]
            }
            requestBody["input"] = inputMessages
            requestBody["tools"] = [
                [
                    "type": "web_search",
                    "max_keyword": 2
                ]
            ]
            print("ğŸ“¤ [LLM] è¯·æ±‚æ¨¡å‹: \(VolcanoConfig.modelName) (è”ç½‘æœç´¢æ¨¡å¼)")
        } else {
            // æ™®é€šæ¨¡å¼ï¼šä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼
            let input = messages.map { message in
                "\(message.role.rawValue): \(message.content)"
            }.joined(separator: "\n")
            requestBody["input"] = input
            print("ğŸ“¤ [LLM] è¯·æ±‚æ¨¡å‹: \(VolcanoConfig.modelName) (æ™®é€šæ¨¡å¼)")
            print("ğŸ“¤ [LLM] è¾“å…¥é•¿åº¦: \(input.count) å­—ç¬¦")
        }

        print("ğŸ“¤ [LLM] æ¶ˆæ¯æ•°é‡: \(messages.count)")

        let jsonData = try JSONSerialization.data(withJSONObject: requestBody)

        let headers = [
            "Content-Type": "application/json",
            "Authorization": "Bearer \(apiKey)"
        ]

        do {
            let response: VolcanoResponsesAPIResponse = try await NetworkManager.shared.request(
                url: url,
                method: "POST",
                headers: headers,
                body: jsonData,
                responseType: VolcanoResponsesAPIResponse.self
            )

            print("âœ… [LLM] æ”¶åˆ°å“åº”ï¼ŒçŠ¶æ€: \(response.status)")

            // ä» output ä¸­æ‰¾åˆ° type="message" çš„é¡¹
            guard let messageOutput = response.output.first(where: { $0.type == "message" }) else {
                print("âŒ [LLM] å“åº”ä¸­æ²¡æœ‰ message ç±»å‹çš„è¾“å‡º")
                throw VolcanoError.emptyResponse
            }

            // æå–æ–‡æœ¬å†…å®¹
            guard let textContent = messageOutput.content?.first(where: { $0.type == "output_text" })?.text else {
                print("âŒ [LLM] æ— æ³•æå–æ–‡æœ¬å†…å®¹")
                throw VolcanoError.emptyResponse
            }

            print("âœ… [LLM] æˆåŠŸè·å–å›å¤ï¼Œé•¿åº¦: \(textContent.count) å­—ç¬¦")

            // æ‰“å° token ä½¿ç”¨æƒ…å†µ
            if let usage = response.usage {
                print("ğŸ“Š [LLM] Token ä½¿ç”¨: è¾“å…¥=\(usage.input_tokens), è¾“å‡º=\(usage.output_tokens), æ€»è®¡=\(usage.total_tokens)")
                if let reasoning = usage.output_tokens_details?.reasoning_tokens {
                    print("ğŸ“Š [LLM] æ¨ç† Token: \(reasoning)")
                }
            }

            return textContent
        } catch let error as URLError {
            print("âŒ [LLM] ç½‘ç»œé”™è¯¯: \(error.localizedDescription)")
            throw VolcanoError.requestFailed("ç½‘ç»œé”™è¯¯: \(error.localizedDescription)")
        } catch let error as DecodingError {
            print("âŒ [LLM] å“åº”è§£æå¤±è´¥: \(error)")
            throw VolcanoError.requestFailed("å“åº”æ ¼å¼é”™è¯¯")
        } catch {
            print("âŒ [LLM] é”™è¯¯: \(error)")
            throw error
        }
    }


    // æµå¼å“åº”ç‰ˆæœ¬ï¼ˆæ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼‰
    func chatStream(messages: [Message], enableWebSearch: Bool = false, onChunk: @escaping (String) -> Void) async throws {
        guard !apiKey.isEmpty else {
            throw VolcanoError.missingAPIKey
        }

        try await chatStreamWithAPIKey(messages: messages, enableWebSearch: enableWebSearch, onChunk: onChunk)
    }

    private func chatStreamWithAPIKey(messages: [Message], enableWebSearch: Bool, onChunk: @escaping (String) -> Void) async throws {
        print("ğŸ”‘ [LLM Stream] æ¨¡æ‹Ÿæµå¼è¾“å‡º")

        // æ£€æµ‹æ˜¯å¦æœ‰å¤šæ¨¡æ€å†…å®¹ï¼ˆå›¾ç‰‡ï¼‰
        let hasMultimodalContent = messages.contains { $0.hasImages }

        // å¤šæ¨¡æ€ä½¿ç”¨ chat/completions APIï¼Œå…¶ä»–ä½¿ç”¨ responses API
        if hasMultimodalContent {
            try await chatStreamWithChatCompletionsAPI(messages: messages, onChunk: onChunk)
        } else {
            try await chatStreamWithResponsesAPI(messages: messages, enableWebSearch: enableWebSearch, onChunk: onChunk)
        }
    }

    // Chat Completions API - æµå¼ç‰ˆæœ¬ï¼ˆæ¨¡æ‹Ÿï¼‰
    private func chatStreamWithChatCompletionsAPI(messages: [Message], onChunk: @escaping (String) -> Void) async throws {
        print("ğŸ–¼ï¸ [LLM Stream] ä½¿ç”¨ Chat Completions API (å¤šæ¨¡æ€æ¨¡å¼)")

        guard let url = URL(string: "https://ark.cn-beijing.volces.com/api/v3/chat/completions") else {
            throw VolcanoError.invalidURL
        }

        // æ„å»ºæ¶ˆæ¯æ•°ç»„
        let messagesArray = messages.map { message -> [String: Any] in
            var messageDict: [String: Any] = ["role": message.role.rawValue]

            if message.hasImages {
                // å¤šæ¨¡æ€æ¶ˆæ¯ï¼šä½¿ç”¨ content æ•°ç»„
                var contentArray: [[String: Any]] = []

                // æ·»åŠ å›¾ç‰‡å†…å®¹
                for attachment in message.imageAttachments {
                    let base64URL = ImageProcessor.toBase64DataURL(data: attachment.data, mimeType: attachment.mimeType)
                    contentArray.append([
                        "type": "image_url",
                        "image_url": ["url": base64URL]
                    ])
                }

                // æ·»åŠ æ–‡æœ¬å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
                if !message.content.isEmpty {
                    contentArray.append([
                        "type": "text",
                        "text": message.content
                    ])
                }

                messageDict["content"] = contentArray
            } else {
                // çº¯æ–‡æœ¬æ¶ˆæ¯
                messageDict["content"] = message.content
            }

            return messageDict
        }

        let requestBody: [String: Any] = [
            "model": VolcanoConfig.modelName,
            "messages": messagesArray
        ]

        let imageCount = messages.reduce(0) { $0 + $1.imageAttachments.count }
        print("ğŸ–¼ï¸ [LLM Stream] åŒ…å«å›¾ç‰‡: \(imageCount) å¼ ")

        let jsonData = try JSONSerialization.data(withJSONObject: requestBody)

        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.httpBody = jsonData
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")

        print("âœ… [LLM Stream] å‘é€è¯·æ±‚...")

        let (data, response) = try await URLSession.shared.data(for: request)

        guard let httpResponse = response as? HTTPURLResponse else {
            throw VolcanoError.invalidResponse
        }

        print("ğŸ“Š [LLM Stream] HTTP çŠ¶æ€ç : \(httpResponse.statusCode)")

        guard (200...299).contains(httpResponse.statusCode) else {
            if let errorString = String(data: data, encoding: .utf8) {
                print("âŒ [LLM Stream] é”™è¯¯è¯¦æƒ…: \(errorString.prefix(500))")
            }
            throw VolcanoError.invalidResponse
        }

        // è§£æå“åº”
        let decoder = JSONDecoder()
        let apiResponse = try decoder.decode(ChatCompletionsResponse.self, from: data)

        print("âœ… [LLM Stream] æ”¶åˆ°å®Œæ•´å“åº”")

        guard let firstChoice = apiResponse.choices.first,
              let textContent = firstChoice.message.content else {
            print("âŒ [LLM Stream] å“åº”ä¸­æ²¡æœ‰å†…å®¹")
            throw VolcanoError.emptyResponse
        }

        print("âœ… [LLM Stream] æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼Œæ€»é•¿åº¦: \(textContent.count) å­—ç¬¦")

        // æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼šé€å­—ç¬¦å‘é€ï¼ˆæ¯æ¬¡å‘é€å¤šä¸ªå­—ç¬¦ä»¥æé«˜é€Ÿåº¦ï¼‰
        let chunkSize = 3
        var index = textContent.startIndex

        while index < textContent.endIndex {
            let endIndex = textContent.index(index, offsetBy: chunkSize, limitedBy: textContent.endIndex) ?? textContent.endIndex
            let chunk = String(textContent[index..<endIndex])
            onChunk(chunk)
            index = endIndex

            try? await Task.sleep(nanoseconds: 10_000_000)
        }

        print("âœ… [LLM Stream] æ¨¡æ‹Ÿæµå¼è¾“å‡ºå®Œæˆ")
    }

    // Responses API - æµå¼ç‰ˆæœ¬ï¼ˆæ¨¡æ‹Ÿï¼‰
    private func chatStreamWithResponsesAPI(messages: [Message], enableWebSearch: Bool, onChunk: @escaping (String) -> Void) async throws {
        print("ğŸ“ [LLM Stream] ä½¿ç”¨ Responses API")
        if enableWebSearch {
            print("ğŸŒ [LLM Stream] å·²å¯ç”¨è”ç½‘æœç´¢")
        }

        guard let url = URL(string: "https://ark.cn-beijing.volces.com/api/v3/responses") else {
            throw VolcanoError.invalidURL
        }

        var requestBody: [String: Any] = [
            "model": VolcanoConfig.modelName
        ]

        if enableWebSearch {
            // è”ç½‘æœç´¢æ¨¡å¼ï¼šä½¿ç”¨æ•°ç»„æ ¼å¼
            let inputMessages = messages.map { message in
                ["role": message.role.rawValue, "content": message.content]
            }
            requestBody["input"] = inputMessages
            requestBody["tools"] = [
                [
                    "type": "web_search",
                    "max_keyword": 2
                ]
            ]
            print("ğŸ“¤ [LLM Stream] è¯·æ±‚æ¨¡å‹: \(VolcanoConfig.modelName) (è”ç½‘æœç´¢æ¨¡å¼)")
        } else {
            // æ™®é€šæ¨¡å¼ï¼šä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼
            let input = messages.map { message in
                "\(message.role.rawValue): \(message.content)"
            }.joined(separator: "\n")
            requestBody["input"] = input
        }

        let jsonData = try JSONSerialization.data(withJSONObject: requestBody)

        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.httpBody = jsonData
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")

        print("âœ… [LLM Stream] å‘é€è¯·æ±‚...")

        let (data, response) = try await URLSession.shared.data(for: request)

        guard let httpResponse = response as? HTTPURLResponse else {
            throw VolcanoError.invalidResponse
        }

        print("ğŸ“Š [LLM Stream] HTTP çŠ¶æ€ç : \(httpResponse.statusCode)")

        guard (200...299).contains(httpResponse.statusCode) else {
            if let errorString = String(data: data, encoding: .utf8) {
                print("âŒ [LLM Stream] é”™è¯¯è¯¦æƒ…: \(errorString.prefix(500))")
            }
            throw VolcanoError.invalidResponse
        }

        // è§£æå“åº”
        let decoder = JSONDecoder()
        let apiResponse = try decoder.decode(VolcanoResponsesAPIResponse.self, from: data)

        print("âœ… [LLM Stream] æ”¶åˆ°å®Œæ•´å“åº”ï¼ŒçŠ¶æ€: \(apiResponse.status)")

        // ä» output ä¸­æ‰¾åˆ° type="message" çš„é¡¹
        guard let messageOutput = apiResponse.output.first(where: { $0.type == "message" }) else {
            print("âŒ [LLM Stream] å“åº”ä¸­æ²¡æœ‰ message ç±»å‹çš„è¾“å‡º")
            throw VolcanoError.emptyResponse
        }

        // æå–æ–‡æœ¬å†…å®¹
        guard let textContent = messageOutput.content?.first(where: { $0.type == "output_text" })?.text else {
            print("âŒ [LLM Stream] æ— æ³•æå–æ–‡æœ¬å†…å®¹")
            throw VolcanoError.emptyResponse
        }

        print("âœ… [LLM Stream] æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼Œæ€»é•¿åº¦: \(textContent.count) å­—ç¬¦")

        // æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼šé€å­—ç¬¦å‘é€ï¼ˆæ¯æ¬¡å‘é€å¤šä¸ªå­—ç¬¦ä»¥æé«˜é€Ÿåº¦ï¼‰
        let chunkSize = 3  // æ¯æ¬¡å‘é€3ä¸ªå­—ç¬¦
        var index = textContent.startIndex

        while index < textContent.endIndex {
            let endIndex = textContent.index(index, offsetBy: chunkSize, limitedBy: textContent.endIndex) ?? textContent.endIndex
            let chunk = String(textContent[index..<endIndex])
            onChunk(chunk)
            index = endIndex

            // çŸ­æš‚å»¶è¿Ÿä»¥æ¨¡æ‹Ÿæµå¼æ•ˆæœï¼ˆå¯é€‰ï¼‰
            try? await Task.sleep(nanoseconds: 10_000_000)  // 10ms
        }

        print("âœ… [LLM Stream] æ¨¡æ‹Ÿæµå¼è¾“å‡ºå®Œæˆ")
    }

}

// MARK: - Response Models for Chat Completions API

struct ChatCompletionsResponse: Codable {
    let id: String
    let object: String
    let created: Int
    let model: String
    let choices: [Choice]
    let usage: Usage?

    struct Choice: Codable {
        let index: Int
        let message: MessageContent
        let finish_reason: String?

        struct MessageContent: Codable {
            let role: String
            let content: String?
        }
    }

    struct Usage: Codable {
        let prompt_tokens: Int
        let completion_tokens: Int
        let total_tokens: Int
    }
}

// MARK: - Response Models for Responses API

struct VolcanoResponsesAPIResponse: Codable {
    let id: String
    let model: String
    let status: String
    let output: [ResponseOutput]
    let usage: Usage?

    struct ResponseOutput: Codable {
        let id: String?
        let type: String
        let role: String?
        let content: [OutputContent]?
        let status: String?
        let summary: [SummaryContent]?

        struct OutputContent: Codable {
            let type: String
            let text: String?
        }

        struct SummaryContent: Codable {
            let type: String
            let text: String?
        }
    }

    struct Usage: Codable {
        let input_tokens: Int
        let output_tokens: Int
        let total_tokens: Int
        let input_tokens_details: InputTokensDetails?
        let output_tokens_details: OutputTokensDetails?

        struct InputTokensDetails: Codable {
            let cached_tokens: Int
        }

        struct OutputTokensDetails: Codable {
            let reasoning_tokens: Int?
        }
    }
}

enum VolcanoError: Error, LocalizedError {
    case missingAPIKey
    case invalidURL
    case invalidResponse
    case emptyResponse
    case requestFailed(String)

    var errorDescription: String? {
        switch self {
        case .missingAPIKey:
            return "æœªé…ç½® API Keyï¼Œè¯·åœ¨æ–¹èˆŸå¹³å°åˆ›å»ºåº”ç”¨å¹¶è·å– API Key"
        case .invalidURL:
            return "API åœ°å€æ— æ•ˆ"
        case .invalidResponse:
            return "æœåŠ¡å™¨å“åº”æ— æ•ˆï¼Œè¯·æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®"
        case .emptyResponse:
            return "æœåŠ¡å™¨è¿”å›ç©ºå“åº”"
        case .requestFailed(let message):
            return message
        }
    }
}
